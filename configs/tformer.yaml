# lightning.pytorch==2.4.0
seed_everything: 0
trainer:
  max_epochs: 10000
  check_val_every_n_epoch: 1
  log_every_n_steps: 1
  num_nodes: 1
  precision: 32
  logger:
    - class_path: lightning.pytorch.loggers.TensorBoardLogger
      init_args: 
        save_dir: Data/Tb
        default_hp_metric: false
        name: overfdataset ## same name
  callbacks:
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "step"
    - class_path: src.utils.ParmSummary
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: Data/Tb
        filename: model-{epoch:02d}-{val_loss:.2f}
        monitor: val_loss
        verbose: false
        save_top_k: 1
        save_weights_only: false
        mode: min


# model
model:
  class_path: src.my_model.transformer.TrackFormer
  init_args:
    input_dim: 3
    model_dim: 128
    num_classes: 1
    num_heads: 4
    num_layers: 2
    warmup: 100
    lr: 0.0005
    dropout: 0.0
    input_dropout: 0.0
    use_scheduler: False
    criterion: qloss-0.2
    
## Dataset
data:
  class_path: src.datasets.datamodules.DataModule
  init_args:
    dataset_type: acts
    dataset_dir: Data/Acts
    batch_size: 256
    use_wrapper: True
    persistance: True
