# TrackFormer: Particle Trackfitting with Transformer 

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/Python-3.7%2B-green.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.10%2B-orange.svg)](https://pytorch.org/)
[![PyTorch Lightning](https://img.shields.io/badge/PyTorch%20Lightning-1.6%2B-purple.svg)](https://www.pytorchlightning.ai/)

## Overview

TrackFormer is our novel approach to particle trajectory reconstruction using transformer-inspired architecture. By leveraging the powerful self-attention mechanism of Transformers, this model is able to effectively capture complex dependencies in particle event data, leading to improved accuracy and efficiency in track fitting tasks.

## Features

- **Transformer-based Architecture**: Our model utilizes a Transformer-based network, allowing efficient and accurate particle track reconstruction.
- **PyTorch Lightning Integration**: The project is built using PyTorch Lightning, a high-level deep learning framework that simplifies model training and evaluation.
- **Modular Design**: The codebase is designed in a modular fashion, making it easy to experiment with different model architectures, loss functions, and training strategies.
- **Comprehensive Logging and Visualization**: The training process is accompanied by detailed logging and visualization capabilities, powered by TensorBoard and other tools

## Getting Started

1. **Clone the repository**:
